[
{
"asset_id":
"7f4fbb15-ff41-4eb9-b556-39000f259dcf",
"blob":
"89168948-8d2f-4494-8151-18634d6b368e",
"created":
"2024-04-02T19:09:23.832176Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:43:37.274254-04:00",
"contentSize":
9122341942,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/7f4fbb15-ff41-4eb9-b556-39000f259dcf/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/891/689/89168948-8d2f-4494-8151-18634d6b368e"
],
"dateModified":
"2024-04-02T15:03:39.596055-04:00",
"digest":
{
"dandi:dandi-etag":
"c900c98fdd320f520f9e07caecfe6835-136",
"dandi:sha2-256":
"d1bbdd6986eb01fa8bd2bdbfc6457a602fab8e4a4c8314c5e4776cdaab1ec797"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:7f4fbb15-ff41-4eb9-b556-39000f259dcf",
"identifier":
"7f4fbb15-ff41-4eb9-b556-39000f259dcf",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210525/sub-210525_ses-20210525T000000_obj-m8j5s1_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210525",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-05-25T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:03:39.596034-04:00",
"id":
"urn:uuid:51020b3d-d898-494c-82e4-726d342dc2ae",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:03:15.520428-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:09:23.832190Z",
"path":
"sub-210525/sub-210525_ses-20210525T000000_obj-m8j5s1_image+ophys.nwb",
"size":
9122341942
},
{
"asset_id":
"5cf07115-d4c1-493a-b6c4-827db40705c9",
"blob":
"e52b8166-d4d7-4508-9f3a-16850a7fd94f",
"created":
"2024-04-02T19:18:24.413988Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:43:45.402254-04:00",
"contentSize":
9084508453,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/5cf07115-d4c1-493a-b6c4-827db40705c9/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/e52/b81/e52b8166-d4d7-4508-9f3a-16850a7fd94f"
],
"dateModified":
"2024-04-02T15:03:39.447031-04:00",
"digest":
{
"dandi:dandi-etag":
"299ffb6e7bcc5efe4305fe1296072ba8-136",
"dandi:sha2-256":
"033caa094aecc530487205ef423bfe7001d4c461330b99af7aac7294df30842d"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:5cf07115-d4c1-493a-b6c4-827db40705c9",
"identifier":
"5cf07115-d4c1-493a-b6c4-827db40705c9",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210525/sub-210525_ses-20210525T000000_obj-xkgj3s_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210525",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-05-25T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:03:39.447007-04:00",
"id":
"urn:uuid:aade399e-5b68-4f16-85ee-208eb012a32a",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:03:14.534723-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:18:24.414017Z",
"path":
"sub-210525/sub-210525_ses-20210525T000000_obj-xkgj3s_image+ophys.nwb",
"size":
9084508453
},
{
"asset_id":
"ad965ac2-4d02-44ce-bca1-5a24d358de23",
"blob":
"6ffb34ca-dae3-40ab-8af6-b138818be088",
"created":
"2024-04-02T19:37:16.831451Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:44:57.866255-04:00",
"contentSize":
9348265338,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/ad965ac2-4d02-44ce-bca1-5a24d358de23/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/6ff/b34/6ffb34ca-dae3-40ab-8af6-b138818be088"
],
"dateModified":
"2024-04-02T15:03:39.133602-04:00",
"digest":
{
"dandi:dandi-etag":
"5e1bb6bee9b91c446c6f29cca2c3045d-140",
"dandi:sha2-256":
"60b4d68ef343f16453c968a1ed04eca67e3a5f3aaaf5d0250869b105bcf7f848"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:ad965ac2-4d02-44ce-bca1-5a24d358de23",
"identifier":
"ad965ac2-4d02-44ce-bca1-5a24d358de23",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210614/sub-210614_ses-20210614T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210614",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-14T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:03:39.133572-04:00",
"id":
"urn:uuid:f5c63e10-1d86-4b76-9153-bdd9084831d3",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:03:13.966741-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:37:16.831465Z",
"path":
"sub-210614/sub-210614_ses-20210614T000000_image+ophys.nwb",
"size":
9348265338
},
{
"asset_id":
"991be16b-a7ba-4022-9cef-0a31329b262a",
"blob":
"969453c0-80bc-4897-a7c0-e1f5526de91b",
"created":
"2024-04-02T19:24:33.081637Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:43:54.038254-04:00",
"contentSize":
9442482781,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/991be16b-a7ba-4022-9cef-0a31329b262a/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/969/453/969453c0-80bc-4897-a7c0-e1f5526de91b"
],
"dateModified":
"2024-04-02T15:03:39.669356-04:00",
"digest":
{
"dandi:dandi-etag":
"e8e6e3f92264aca83ae422023618114a-141",
"dandi:sha2-256":
"e6689d9b3a3cdaa0e0cf7ce0a20b3ad4866cb9bf07034d40931618086d2d9abc"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:991be16b-a7ba-4022-9cef-0a31329b262a",
"identifier":
"991be16b-a7ba-4022-9cef-0a31329b262a",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210618/sub-210618_ses-20210618T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210618",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-18T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:03:39.669324-04:00",
"id":
"urn:uuid:ee6a183a-475c-4798-b218-b84ee691f888",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:03:16.243594-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:24:33.081656Z",
"path":
"sub-210618/sub-210618_ses-20210618T000000_image+ophys.nwb",
"size":
9442482781
},
{
"asset_id":
"925a188f-fb51-48e9-80d9-a68d33396ea9",
"blob":
"49b8c8e5-a1e4-4a9d-bd2c-53a041c813f5",
"created":
"2024-04-02T20:11:01.696450Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:46:29.754256-04:00",
"contentSize":
9245391262,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/925a188f-fb51-48e9-80d9-a68d33396ea9/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/49b/8c8/49b8c8e5-a1e4-4a9d-bd2c-53a041c813f5"
],
"dateModified":
"2024-04-02T15:03:39.316348-04:00",
"digest":
{
"dandi:dandi-etag":
"7bd7d28cdb9d720c4a15966eddf4443b-138",
"dandi:sha2-256":
"265ec56fd53bedc9c37b806f3ae9d145b413c38f5952c2b3cf445f04f8424baf"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:925a188f-fb51-48e9-80d9-a68d33396ea9",
"identifier":
"925a188f-fb51-48e9-80d9-a68d33396ea9",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210623/sub-210623_ses-20210623T000000_obj-1m8hybt_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210623",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-23T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:03:39.316321-04:00",
"id":
"urn:uuid:c1e24124-74be-4a73-9c81-67d89ef171f1",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:03:13.921817-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:11:01.696466Z",
"path":
"sub-210623/sub-210623_ses-20210623T000000_obj-1m8hybt_image+ophys.nwb",
"size":
9245391262
},
{
"asset_id":
"25ed5f57-e0ff-4408-b6e6-703102464f43",
"blob":
"87d9d7c5-3e3c-4d0b-a7fe-401e469ead20",
"created":
"2024-04-02T19:29:45.024123Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:44:01.846255-04:00",
"contentSize":
9632825823,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/25ed5f57-e0ff-4408-b6e6-703102464f43/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/87d/9d7/87d9d7c5-3e3c-4d0b-a7fe-401e469ead20"
],
"dateModified":
"2024-04-02T15:09:30.599570-04:00",
"digest":
{
"dandi:dandi-etag":
"c31b6ba6df255477b1ec4593b72c99e9-144",
"dandi:sha2-256":
"9ceba37a23e8da72aa3cd8e091b3843e007057a31bf8e7075371db207fa57f0a"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:25ed5f57-e0ff-4408-b6e6-703102464f43",
"identifier":
"25ed5f57-e0ff-4408-b6e6-703102464f43",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210623/sub-210623_ses-20210623T000000_obj-nth9tu_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210623",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-23T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:09:30.599554-04:00",
"id":
"urn:uuid:f60560ed-bf73-45c7-901e-33b700849d2d",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:09:25.689069-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:29:45.024137Z",
"path":
"sub-210623/sub-210623_ses-20210623T000000_obj-nth9tu_image+ophys.nwb",
"size":
9632825823
},
{
"asset_id":
"c0ca0492-9adf-469e-9107-3e35f1f228ba",
"blob":
"e52f9772-bef1-458c-a550-4208d2330fff",
"created":
"2024-04-02T19:28:36.729780Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:44:10.670254-04:00",
"contentSize":
9333644193,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/c0ca0492-9adf-469e-9107-3e35f1f228ba/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/e52/f97/e52f9772-bef1-458c-a550-4208d2330fff"
],
"dateModified":
"2024-04-02T15:18:28.816762-04:00",
"digest":
{
"dandi:dandi-etag":
"f4b9d90b18ff90f46ca334c361d1add1-140",
"dandi:sha2-256":
"16d64282e69941cefd7fce3c17e5ba6d7327cb9136b759bdc9521539a7b37392"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:c0ca0492-9adf-469e-9107-3e35f1f228ba",
"identifier":
"c0ca0492-9adf-469e-9107-3e35f1f228ba",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210624/sub-210624_ses-20210624T000000_obj-18t97nu_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210624",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-24T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:18:28.816746-04:00",
"id":
"urn:uuid:d426d1a4-2ab4-4599-b92a-caba527d1bdd",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:18:24.658955-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:28:36.729833Z",
"path":
"sub-210624/sub-210624_ses-20210624T000000_obj-18t97nu_image+ophys.nwb",
"size":
9333644193
},
{
"asset_id":
"1914d591-3024-4c03-82b9-03e2b44a8283",
"blob":
"2cd17205-092d-4605-a567-38fcc603745f",
"created":
"2024-04-02T19:36:39.295061Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:46:37.154256-04:00",
"contentSize":
9465159021,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/1914d591-3024-4c03-82b9-03e2b44a8283/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/2cd/172/2cd17205-092d-4605-a567-38fcc603745f"
],
"dateModified":
"2024-04-02T15:24:36.503519-04:00",
"digest":
{
"dandi:dandi-etag":
"821f960e188189c43c86e17f9ddee347-142",
"dandi:sha2-256":
"b19160c0daefe60a5a20495c14d028424b2881fd365abe8fbd146aee9cdc8776"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:1914d591-3024-4c03-82b9-03e2b44a8283",
"identifier":
"1914d591-3024-4c03-82b9-03e2b44a8283",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210624/sub-210624_ses-20210624T000000_obj-tp8l4b_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210624",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-24T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:24:36.503503-04:00",
"id":
"urn:uuid:9a2d54a7-eed5-44ea-89ac-d8eae5ac174d",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:24:32.312273-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:36:39.295080Z",
"path":
"sub-210624/sub-210624_ses-20210624T000000_obj-tp8l4b_image+ophys.nwb",
"size":
9465159021
},
{
"asset_id":
"2a62a8da-a115-4380-a416-881d2f70a4e3",
"blob":
"98dbc712-2434-41f9-9f95-259003f78cd5",
"created":
"2024-04-02T19:30:42.494866Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:46:44.642256-04:00",
"contentSize":
9373035995,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/2a62a8da-a115-4380-a416-881d2f70a4e3/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/98d/bc7/98dbc712-2434-41f9-9f95-259003f78cd5"
],
"dateModified":
"2024-04-02T15:28:40.033448-04:00",
"digest":
{
"dandi:dandi-etag":
"f6e931513b48ffd5540b8ed0783965b3-140",
"dandi:sha2-256":
"4288eba4dd776dcb0fde5c3817d2cf5503033d9e63144f5b7d1bcd1a69468e6d"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:2a62a8da-a115-4380-a416-881d2f70a4e3",
"identifier":
"2a62a8da-a115-4380-a416-881d2f70a4e3",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210626/sub-210626_ses-20210626T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210626",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-26T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:28:40.033433-04:00",
"id":
"urn:uuid:bea5df94-de97-428b-bdef-089bccfef7fa",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:28:35.838938-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:30:42.494882Z",
"path":
"sub-210626/sub-210626_ses-20210626T000000_image+ophys.nwb",
"size":
9373035995
},
{
"asset_id":
"fe0ac315-c0b9-4334-bfab-a12f7f0037d7",
"blob":
"6c8faa72-d309-4c8d-a32c-ce1a0a534e3c",
"created":
"2024-04-02T20:14:29.566841Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:46:52.246256-04:00",
"contentSize":
9334103925,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/fe0ac315-c0b9-4334-bfab-a12f7f0037d7/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/6c8/faa/6c8faa72-d309-4c8d-a32c-ce1a0a534e3c"
],
"dateModified":
"2024-04-02T15:29:50.012791-04:00",
"digest":
{
"dandi:dandi-etag":
"d9740eefba367157e6792927ac04e555-140",
"dandi:sha2-256":
"3996db93a0461f25945801147d5825c307b298773bc57e7b45b14e9f8e8aa399"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:fe0ac315-c0b9-4334-bfab-a12f7f0037d7",
"identifier":
"fe0ac315-c0b9-4334-bfab-a12f7f0037d7",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210627/sub-210627_ses-20210627T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210627",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-27T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:29:50.012776-04:00",
"id":
"urn:uuid:3c0cfc6a-9390-4d5e-aab0-86d00ab78080",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:29:45.311906-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:14:29.566859Z",
"path":
"sub-210627/sub-210627_ses-20210627T000000_image+ophys.nwb",
"size":
9334103925
},
{
"asset_id":
"9945a804-fb7d-4e72-bc59-027338e7ec6c",
"blob":
"de892b50-7930-48ca-99a5-cc9505029752",
"created":
"2024-04-02T20:04:58.093837Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:47:00.066256-04:00",
"contentSize":
9864051576,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/9945a804-fb7d-4e72-bc59-027338e7ec6c/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/de8/92b/de892b50-7930-48ca-99a5-cc9505029752"
],
"dateModified":
"2024-04-02T15:30:48.068449-04:00",
"digest":
{
"dandi:dandi-etag":
"4f39249f6cbeef34975f96ffc68655af-147",
"dandi:sha2-256":
"2b5dfd4f01af15a7eec50e7496dc11de73d462b986b87729d12fa477efa247a8"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:9945a804-fb7d-4e72-bc59-027338e7ec6c",
"identifier":
"9945a804-fb7d-4e72-bc59-027338e7ec6c",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210630/sub-210630_ses-20210630T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210630",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-06-30T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:30:48.068433-04:00",
"id":
"urn:uuid:8b466aef-ce24-4e83-a8db-57505eb05372",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:30:43.320416-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:04:58.093851Z",
"path":
"sub-210630/sub-210630_ses-20210630T000000_image+ophys.nwb",
"size":
9864051576
},
{
"asset_id":
"df6ba783-38e7-4608-b8e0-edf6546fb30f",
"blob":
"f015aded-c4f3-4ef5-8084-bd5fa4280300",
"created":
"2024-04-02T19:53:12.230136Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:45:05.206255-04:00",
"contentSize":
9167804832,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/df6ba783-38e7-4608-b8e0-edf6546fb30f/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/f01/5ad/f015aded-c4f3-4ef5-8084-bd5fa4280300"
],
"dateModified":
"2024-04-02T15:36:43.349336-04:00",
"digest":
{
"dandi:dandi-etag":
"f8f823452453dca1404be5fcfa2022c9-137",
"dandi:sha2-256":
"0cd75e44f6e237c6590802054a4df126b013f06ab73968011973079f1e327960"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:df6ba783-38e7-4608-b8e0-edf6546fb30f",
"identifier":
"df6ba783-38e7-4608-b8e0-edf6546fb30f",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210727/sub-210727_ses-20210727T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210727",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-07-27T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:36:43.349316-04:00",
"id":
"urn:uuid:70633180-307d-42a4-a95e-8d3d6d5b0c71",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:36:39.149499-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:53:12.230150Z",
"path":
"sub-210727/sub-210727_ses-20210727T000000_image+ophys.nwb",
"size":
9167804832
},
{
"asset_id":
"d66bd179-ae25-4bd4-81b5-df37d5421424",
"blob":
"742b7375-e1bf-40cd-83be-1a12ba1164b4",
"created":
"2024-04-02T19:40:17.925309Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:45:12.882255-04:00",
"contentSize":
9344421081,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/d66bd179-ae25-4bd4-81b5-df37d5421424/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/742/b73/742b7375-e1bf-40cd-83be-1a12ba1164b4"
],
"dateModified":
"2024-04-02T15:37:23.112353-04:00",
"digest":
{
"dandi:dandi-etag":
"3dae18e3ab65efd4d3615751d5572eba-140",
"dandi:sha2-256":
"feb5474c6f80755fe5c38ff4b5d4a1a84d4330403f300ebe08a97aeaaafe5610"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:d66bd179-ae25-4bd4-81b5-df37d5421424",
"identifier":
"d66bd179-ae25-4bd4-81b5-df37d5421424",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210729/sub-210729_ses-20210729T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210729",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-07-29T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:37:23.112337-04:00",
"id":
"urn:uuid:cc13ebb7-18eb-40bf-8417-34ce70ff858e",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:37:18.231584-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T19:40:17.925327Z",
"path":
"sub-210729/sub-210729_ses-20210729T000000_image+ophys.nwb",
"size":
9344421081
},
{
"asset_id":
"1471f9bb-96e0-4289-aa0f-d0d6debe2439",
"blob":
"03d49071-2851-44d6-a886-549c366d8a94",
"created":
"2024-04-02T20:10:56.900034Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:45:20.738255-04:00",
"contentSize":
9226328066,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/1471f9bb-96e0-4289-aa0f-d0d6debe2439/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/03d/490/03d49071-2851-44d6-a886-549c366d8a94"
],
"dateModified":
"2024-04-02T15:40:21.559077-04:00",
"digest":
{
"dandi:dandi-etag":
"3372e0082a48177551affd604c9d77b6-138",
"dandi:sha2-256":
"2208c1f3712b3e44d16dcfe4aa618a9b6f4e9c483e6c7eda180f98d1647c1b83"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:1471f9bb-96e0-4289-aa0f-d0d6debe2439",
"identifier":
"1471f9bb-96e0-4289-aa0f-d0d6debe2439",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210802/sub-210802_ses-20210802T000000_obj-10sjn9q_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210802",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-02T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:40:21.559061-04:00",
"id":
"urn:uuid:29bd8f4a-c1bf-4663-bf0a-db1669827d5b",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:40:17.335605-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:10:56.900051Z",
"path":
"sub-210802/sub-210802_ses-20210802T000000_obj-10sjn9q_image+ophys.nwb",
"size":
9226328066
},
{
"asset_id":
"c272d929-0022-483c-9199-1457b417be52",
"blob":
"d576db9a-e1bb-4d33-b80a-2ae739cfc9c9",
"created":
"2024-04-02T20:21:17.225173Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:47:07.814256-04:00",
"contentSize":
9240761985,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/c272d929-0022-483c-9199-1457b417be52/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/d57/6db/d576db9a-e1bb-4d33-b80a-2ae739cfc9c9"
],
"dateModified":
"2024-04-02T15:53:15.445099-04:00",
"digest":
{
"dandi:dandi-etag":
"ee949bdf9379b1ba2f9a35f058c857bf-138",
"dandi:sha2-256":
"df226b247d4d99d07e6b5e1512ce0b71a7744b1cd8b3b47dea38547ecccb7fa8"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:c272d929-0022-483c-9199-1457b417be52",
"identifier":
"c272d929-0022-483c-9199-1457b417be52",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210802/sub-210802_ses-20210802T000000_obj-qj74lz_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210802",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-02T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T15:53:15.445083-04:00",
"id":
"urn:uuid:819d2cf7-7e41-40f8-be3f-9919d09bf87b",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T15:53:11.232806-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:21:17.225186Z",
"path":
"sub-210802/sub-210802_ses-20210802T000000_obj-qj74lz_image+ophys.nwb",
"size":
9240761985
},
{
"asset_id":
"2c0f7ec2-2330-4401-a7ed-05dc7964bca1",
"blob":
"2411b2a4-7733-4e3e-bcc3-5df999dd3bc7",
"created":
"2024-04-02T20:37:10.157459Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:45:28.794255-04:00",
"contentSize":
9197624908,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/2c0f7ec2-2330-4401-a7ed-05dc7964bca1/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/241/1b2/2411b2a4-7733-4e3e-bcc3-5df999dd3bc7"
],
"dateModified":
"2024-04-02T16:05:02.026044-04:00",
"digest":
{
"dandi:dandi-etag":
"00d468206d7fbaf3c60f649a9ce509cd-138",
"dandi:sha2-256":
"e67820597227ee7d0fcd37ca89aa091c0fe18431cb9c8892dbbdd0ce33a742bc"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:2c0f7ec2-2330-4401-a7ed-05dc7964bca1",
"identifier":
"2c0f7ec2-2330-4401-a7ed-05dc7964bca1",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210803/sub-210803_ses-20210803T000000_obj-16wmwvt_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210803",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-03T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T16:05:02.026028-04:00",
"id":
"urn:uuid:d5440dad-c128-47e8-831e-70c79e0a0d97",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T16:04:57.815762-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:37:10.157478Z",
"path":
"sub-210803/sub-210803_ses-20210803T000000_obj-16wmwvt_image+ophys.nwb",
"size":
9197624908
},
{
"asset_id":
"a322e7e5-7da8-46d9-88fb-2154373197c9",
"blob":
"901297ec-94a1-40ab-859f-4a21576e6829",
"created":
"2024-04-02T20:49:47.071931Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:45:36.350255-04:00",
"contentSize":
9208081028,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/a322e7e5-7da8-46d9-88fb-2154373197c9/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/901/297/901297ec-94a1-40ab-859f-4a21576e6829"
],
"dateModified":
"2024-04-02T16:11:01.004208-04:00",
"digest":
{
"dandi:dandi-etag":
"cf799f110cef478ccb3d3f1226d32a52-138",
"dandi:sha2-256":
"abbc9fe8970b11037c0cae165cd9ae3538f154920a1aa802e4ec846cc6d6a3c4"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:a322e7e5-7da8-46d9-88fb-2154373197c9",
"identifier":
"a322e7e5-7da8-46d9-88fb-2154373197c9",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210803/sub-210803_ses-20210803T000000_obj-1vn3zp2_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210803",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-03T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T16:11:01.004194-04:00",
"id":
"urn:uuid:98209fe5-dc71-4ddf-8c06-9e30dbbaa71f",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T16:10:56.641768-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:49:47.071945Z",
"path":
"sub-210803/sub-210803_ses-20210803T000000_obj-1vn3zp2_image+ophys.nwb",
"size":
9208081028
},
{
"asset_id":
"0a64cde4-a409-4f87-b072-781fd61ce248",
"blob":
"04788465-4be2-4a34-b2f4-3f3b8696dd50",
"created":
"2024-04-02T20:41:25.914113Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:47:15.278257-04:00",
"contentSize":
9403275619,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/0a64cde4-a409-4f87-b072-781fd61ce248/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/047/884/04788465-4be2-4a34-b2f4-3f3b8696dd50"
],
"dateModified":
"2024-04-02T16:11:06.384229-04:00",
"digest":
{
"dandi:dandi-etag":
"483ff7b043f24e7e421bedd7ec7f2754-141",
"dandi:sha2-256":
"952c880d2b9caeace6198369dda5141f2aef37fff4a615264e278eb6a2016f12"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:0a64cde4-a409-4f87-b072-781fd61ce248",
"identifier":
"0a64cde4-a409-4f87-b072-781fd61ce248",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210803/sub-210803_ses-20210803T000000_obj-3pt5if_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210803",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-03T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T16:11:06.384212-04:00",
"id":
"urn:uuid:d5b91790-7656-40e7-9d98-619177088b59",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T16:11:01.782069-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:41:25.914127Z",
"path":
"sub-210803/sub-210803_ses-20210803T000000_obj-3pt5if_image+ophys.nwb",
"size":
9403275619
},
{
"asset_id":
"d5d9e22a-8efd-499c-b231-6e5d0a91f6bd",
"blob":
"f25d44c1-04de-4d0e-9de2-a275e6d94ceb",
"created":
"2024-04-02T20:50:37.855407Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:47:22.718257-04:00",
"contentSize":
9079004333,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/d5d9e22a-8efd-499c-b231-6e5d0a91f6bd/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/f25/d44/f25d44c1-04de-4d0e-9de2-a275e6d94ceb"
],
"dateModified":
"2024-04-02T16:14:33.328746-04:00",
"digest":
{
"dandi:dandi-etag":
"33ce766f505a2d22e70d8ada70ba00c5-136",
"dandi:sha2-256":
"514ccc5e59b629360555c782f06c868c4f076b062942d52809218b5b8a7b856c"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:d5d9e22a-8efd-499c-b231-6e5d0a91f6bd",
"identifier":
"d5d9e22a-8efd-499c-b231-6e5d0a91f6bd",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210804/sub-210804_ses-20210804T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210804",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-04T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T16:14:33.328730-04:00",
"id":
"urn:uuid:0b09515c-95dc-4b45-a7ea-e780b71fb5c7",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T16:14:29.091633-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:50:37.855425Z",
"path":
"sub-210804/sub-210804_ses-20210804T000000_image+ophys.nwb",
"size":
9079004333
},
{
"asset_id":
"02f8b789-07ff-4234-b960-4c0f662cf25d",
"blob":
"78c8f887-8bb6-4570-977f-caff595b387c",
"created":
"2024-04-02T20:39:08.778994Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:47:37.922257-04:00",
"contentSize":
9217372222,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/02f8b789-07ff-4234-b960-4c0f662cf25d/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/78c/8f8/78c8f887-8bb6-4570-977f-caff595b387c"
],
"dateModified":
"2024-04-02T16:37:13.426452-04:00",
"digest":
{
"dandi:dandi-etag":
"2142ad338e8254911a32d8c758ad6829-138",
"dandi:sha2-256":
"1949fc4ef3fbe6e7719fb6107be78b93fd86fea9361ac755656c7e6318dcf71b"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:02f8b789-07ff-4234-b960-4c0f662cf25d",
"identifier":
"02f8b789-07ff-4234-b960-4c0f662cf25d",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210819/sub-210819_ses-20210819T000000_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210819",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-19T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T16:37:13.426437-04:00",
"id":
"urn:uuid:a20ee459-06f5-48fb-ae31-569f36fb83ac",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T16:37:09.215975-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:39:08.779011Z",
"path":
"sub-210819/sub-210819_ses-20210819T000000_image+ophys.nwb",
"size":
9217372222
},
{
"asset_id":
"8e21a343-4f06-4dfc-8e27-7ea55f3fdfb8",
"blob":
"e810f645-81e7-4878-b818-f4b4552dfc06",
"created":
"2024-04-02T20:41:43.268124Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:48:02.694257-04:00",
"contentSize":
6317546702,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/8e21a343-4f06-4dfc-8e27-7ea55f3fdfb8/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/e81/0f6/e810f645-81e7-4878-b818-f4b4552dfc06"
],
"dateModified":
"2024-04-02T16:41:25.419915-04:00",
"digest":
{
"dandi:dandi-etag":
"f10bb2a2d6f6bd0805060a46db1de1d3-95",
"dandi:sha2-256":
"2af2d767c4d2d397da04a9c42528dd1d8d0e32ca843db6dd9aa49db98cc592e9"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:8e21a343-4f06-4dfc-8e27-7ea55f3fdfb8",
"identifier":
"8e21a343-4f06-4dfc-8e27-7ea55f3fdfb8",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210823/sub-210823_ses-20210823T000000_obj-1tsmyso_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210823",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-23T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T16:41:25.419900-04:00",
"id":
"urn:uuid:3471cc8e-428c-4b51-bf84-86fd1d781798",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T16:41:21.207016-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:41:43.268142Z",
"path":
"sub-210823/sub-210823_ses-20210823T000000_obj-1tsmyso_image+ophys.nwb",
"size":
6317546702
},
{
"asset_id":
"d3ef3156-505c-46e0-a120-b1717307c4fa",
"blob":
"7f48572c-7a9e-432b-b9ca-692d918f7bec",
"created":
"2024-04-02T20:43:38.803581Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:47:54.022257-04:00",
"contentSize":
8990920678,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/d3ef3156-505c-46e0-a120-b1717307c4fa/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/7f4/857/7f48572c-7a9e-432b-b9ca-692d918f7bec"
],
"dateModified":
"2024-04-02T16:41:46.354740-04:00",
"digest":
{
"dandi:dandi-etag":
"6c11ecb010353f780c5ec038751ca1ab-134",
"dandi:sha2-256":
"c80aabe2fad489e34cf0ca5d8234d32c1d245b377631b4e1380808fd786d7131"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:d3ef3156-505c-46e0-a120-b1717307c4fa",
"identifier":
"d3ef3156-505c-46e0-a120-b1717307c4fa",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210823/sub-210823_ses-20210823T000000_obj-pi0l2h_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210823",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-23T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T16:41:46.354725-04:00",
"id":
"urn:uuid:25406b9f-8363-447a-8390-229101949faa",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T16:41:42.134041-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:43:38.803599Z",
"path":
"sub-210823/sub-210823_ses-20210823T000000_obj-pi0l2h_image+ophys.nwb",
"size":
8990920678
},
{
"asset_id":
"d3906499-e728-4a33-9182-ee59f01f2763",
"blob":
"10bfb9e6-b773-4e5d-9280-ef8e98146494",
"created":
"2024-04-02T20:45:32.530423Z",
"metadata":
{
"@context":
"https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.7/context.json",
"access":
[
{
"schemaKey":
"AccessRequirements",
"status":
"dandi:OpenAccess"
}
],
"approach":
[
{
"name":
"microscopy approach; cell population imaging",
"schemaKey":
"ApproachType"
}
],
"blobDateModified":
"2024-04-02T11:44:18.554255-04:00",
"contentSize":
9096244589,
"contentUrl":
[
"https://api.dandiarchive.org/api/assets/d3906499-e728-4a33-9182-ee59f01f2763/download/",
"https://dandiarchive.s3.amazonaws.com/blobs/10b/fb9/10bfb9e6-b773-4e5d-9280-ef8e98146494"
],
"dateModified":
"2024-04-02T16:43:42.776040-04:00",
"digest":
{
"dandi:dandi-etag":
"e230084951b2bda97efa350a1820b358-136",
"dandi:sha2-256":
"97f0c05b3ebb9a53b3ff2607cf33ddec6627210cda685876e3c99368a0c034af"
},
"encodingFormat":
"application/x-nwb",
"id":
"dandiasset:d3906499-e728-4a33-9182-ee59f01f2763",
"identifier":
"d3906499-e728-4a33-9182-ee59f01f2763",
"keywords":
[
"optical physiology",
"fly",
"behavior",
"deep learning"
],
"measurementTechnique":
[
{
"name":
"analytical technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"two-photon microscopy technique",
"schemaKey":
"MeasurementTechniqueType"
},
{
"name":
"surgical technique",
"schemaKey":
"MeasurementTechniqueType"
}
],
"path":
"sub-210827/sub-210827_ses-20210827T000000_obj-1dlkfl0_image+ophys.nwb",
"schemaKey":
"Asset",
"schemaVersion":
"0.6.7",
"variableMeasured":
[
{
"schemaKey":
"PropertyValue",
"value":
"ProcessingModule"
},
{
"schemaKey":
"PropertyValue",
"value":
"PlaneSegmentation"
},
{
"schemaKey":
"PropertyValue",
"value":
"OpticalChannel"
},
{
"schemaKey":
"PropertyValue",
"value":
"ImagingPlane"
},
{
"schemaKey":
"PropertyValue",
"value":
"TwoPhotonSeries"
}
],
"wasAttributedTo":
[
{
"age":
{
"schemaKey":
"PropertyValue",
"unitText":
"ISO-8601 duration",
"value":
"P4D/P7D",
"valueReference":
{
"schemaKey":
"PropertyValue",
"value":
"dandi:BirthReference"
}
},
"identifier":
"210827",
"schemaKey":
"Participant",
"sex":
{
"identifier":
"http://purl.obolibrary.org/obo/PATO_0000384",
"name":
"Male",
"schemaKey":
"SexType"
},
"species":
{
"identifier":
"http://purl.obolibrary.org/obo/NCBITaxon_7227",
"name":
"Drosophila melanogaster - Fruit fly",
"schemaKey":
"SpeciesType"
}
}
],
"wasGeneratedBy":
[
{
"description":
"The rich variety of behaviors observed in animals arises through the interplay between sensory processing and motor control. To understand these sensorimotor transformations, it is useful to build models that predict not only neural responses to sensory input but also how each neuron causally contributes to behavior. Here we demonstrate a novel modeling approach to identify a one-to-one mapping between internal units in a deep neural network and real neurons by predicting the behavioral changes arising from systematic perturbations of more than a dozen neuronal cell types. A key ingredient we introduce is “knockout training”, which involves perturbing the network during training to match the perturbations of the real neurons during behavioral experiments. We apply this approach to model the sensorimotor transformations of Drosophila melanogaster males during a complex, visually-guided social behavior. The visual projection neurons at the interface between the optic lobe and central brain form a set of discrete channels, and prior work indicates that each channel encodes a specific visual feature to drive a particular behavior. Our model reaches a different conclusion---Combinations of visual projection neurons, including those involved in non-social behaviors, drive male interactions with the female, forming a rich population code for behavior. Overall, our framework consolidates behavioral effects elicited from various neural perturbations into a single, unified model, providing a map from stimulus to neuronal cell type to behavior, and enabling future incorporation of the brain’s wiring diagram into the model.",
"name":
"Acquisition session",
"schemaKey":
"Session",
"startDate":
"2021-08-27T00:00:00-04:00"
},
{
"description":
"Metadata generated by DANDI cli",
"endDate":
"2024-04-02T16:43:42.776024-04:00",
"id":
"urn:uuid:ff8cab76-3c44-4bd6-ac72-1af978148bf3",
"name":
"Metadata generation",
"schemaKey":
"Activity",
"startDate":
"2024-04-02T16:43:38.533835-04:00",
"wasAssociatedWith":
[
{
"identifier":
"RRID:SCR_019009",
"name":
"DANDI Command Line Interface",
"schemaKey":
"Software",
"url":
"https://github.com/dandi/dandi-cli",
"version":
"0.61.2"
}
]
}
]
},
"modified":
"2024-04-02T20:45:32.530442Z",
"path":
"sub-210827/sub-210827_ses-20210827T000000_obj-1dlkfl0_image+ophys.nwb",
"size":
9096244589
}
]